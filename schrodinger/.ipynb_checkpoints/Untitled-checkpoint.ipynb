{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/oscar/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 128\n",
    "seedmax = 20 # opens seed files 0 - 19. Lost too much data due to kernel crashes, so these got broken up\n",
    "trainx = []\n",
    "trainy = []\n",
    "validx = []\n",
    "validy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not a ... pythonic [barf]... way of reading data, but python is stupid about pointers, so deal with it\n",
    "for i in range(seedmax):\n",
    "    with open('test_pots'+str(i)+'.csv', 'r') as csvfile:\n",
    "        flurg = csv.reader(csvfile)\n",
    "        for row in flurg:\n",
    "            trainx.append([float(num) for num in row])\n",
    "    with open('test_out'+str(i)+'.csv', 'r') as csvfile:\n",
    "        flurg = csv.reader(csvfile)\n",
    "        for row in flurg:\n",
    "            trainy.append([float(num) for num in row])\n",
    "    with open('valid_pots'+str(i)+'.csv', 'r') as csvfile:\n",
    "        flurg = csv.reader(csvfile)\n",
    "        for row in flurg:\n",
    "            validx.append([float(num) for num in row])\n",
    "    with open('valid_out'+str(i)+'.csv', 'r') as csvfile:\n",
    "        flurg = csv.reader(csvfile)\n",
    "        for row in flurg:\n",
    "            validy.append([float(num) for num in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(127, input_dim=127, activation='softplus'))\n",
    "model.add(Dense(127, activation='softplus'))\n",
    "model.add(Dense(127, activation='softplus'))\n",
    "model.add(Dense(127, activation='softplus'))\n",
    "model.add(Dense(127, activation='softplus'))\n",
    "model.add(Dense(127, activation='softplus'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = np.array(trainx)\n",
    "trainy = np.array(trainy)\n",
    "validx = np.array(validx)\n",
    "validy = np.array(validy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oscar/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100000\n",
      " - 1s - loss: 2.3903 - accuracy: 0.0132\n",
      "Epoch 2/100000\n",
      " - 1s - loss: 0.2594 - accuracy: 0.0147\n",
      "Epoch 3/100000\n",
      " - 1s - loss: 0.1848 - accuracy: 0.0234\n",
      "Epoch 4/100000\n",
      " - 1s - loss: 0.1435 - accuracy: 0.0314\n",
      "Epoch 5/100000\n",
      " - 1s - loss: 0.1128 - accuracy: 0.0375\n",
      "Epoch 6/100000\n",
      " - 1s - loss: 0.0935 - accuracy: 0.0432\n",
      "Epoch 7/100000\n",
      " - 1s - loss: 0.0760 - accuracy: 0.0501\n",
      "Epoch 8/100000\n",
      " - 1s - loss: 0.0630 - accuracy: 0.0501\n",
      "Epoch 9/100000\n",
      " - 1s - loss: 0.0573 - accuracy: 0.0600\n",
      "Epoch 10/100000\n",
      " - 1s - loss: 0.0530 - accuracy: 0.0602\n",
      "Epoch 11/100000\n",
      " - 1s - loss: 0.0435 - accuracy: 0.0686\n",
      "Epoch 12/100000\n",
      " - 1s - loss: 0.0461 - accuracy: 0.0690\n",
      "Epoch 13/100000\n",
      " - 1s - loss: 0.0347 - accuracy: 0.0768\n",
      "Epoch 14/100000\n",
      " - 1s - loss: 0.0314 - accuracy: 0.0806\n",
      "Epoch 15/100000\n",
      " - 1s - loss: 0.0295 - accuracy: 0.0843\n",
      "Epoch 16/100000\n",
      " - 1s - loss: 0.0281 - accuracy: 0.0859\n",
      "Epoch 17/100000\n",
      " - 1s - loss: 0.0255 - accuracy: 0.0881\n",
      "Epoch 18/100000\n",
      " - 1s - loss: 0.0229 - accuracy: 0.0955\n",
      "Epoch 19/100000\n",
      " - 1s - loss: 0.0271 - accuracy: 0.0910\n",
      "Epoch 20/100000\n",
      " - 1s - loss: 0.0212 - accuracy: 0.0973\n",
      "Epoch 21/100000\n",
      " - 1s - loss: 0.0217 - accuracy: 0.1035\n",
      "Epoch 22/100000\n",
      " - 1s - loss: 0.0255 - accuracy: 0.0955\n",
      "Epoch 23/100000\n",
      " - 1s - loss: 0.0175 - accuracy: 0.1064\n",
      "Epoch 24/100000\n",
      " - 1s - loss: 0.0179 - accuracy: 0.1082\n",
      "Epoch 25/100000\n",
      " - 1s - loss: 0.0170 - accuracy: 0.1136\n",
      "Epoch 26/100000\n",
      " - 1s - loss: 0.0160 - accuracy: 0.1164\n",
      "Epoch 27/100000\n",
      " - 1s - loss: 0.0149 - accuracy: 0.1170\n",
      "Epoch 28/100000\n",
      " - 1s - loss: 0.0163 - accuracy: 0.1142\n",
      "Epoch 29/100000\n",
      " - 1s - loss: 0.0140 - accuracy: 0.1190\n",
      "Epoch 30/100000\n",
      " - 1s - loss: 0.0139 - accuracy: 0.1224\n",
      "Epoch 31/100000\n",
      " - 1s - loss: 0.0171 - accuracy: 0.1177\n",
      "Epoch 32/100000\n",
      " - 1s - loss: 0.0147 - accuracy: 0.1265\n",
      "Epoch 33/100000\n",
      " - 1s - loss: 0.0124 - accuracy: 0.1349\n",
      "Epoch 34/100000\n",
      " - 1s - loss: 0.0111 - accuracy: 0.1351\n",
      "Epoch 35/100000\n",
      " - 1s - loss: 0.0163 - accuracy: 0.1211\n",
      "Epoch 36/100000\n",
      " - 1s - loss: 0.0116 - accuracy: 0.1381\n",
      "Epoch 37/100000\n",
      " - 1s - loss: 0.0130 - accuracy: 0.1354\n",
      "Epoch 38/100000\n",
      " - 1s - loss: 0.0157 - accuracy: 0.1225\n",
      "Epoch 39/100000\n",
      " - 1s - loss: 0.0127 - accuracy: 0.1365\n",
      "Epoch 40/100000\n",
      " - 1s - loss: 0.0146 - accuracy: 0.1293\n",
      "Epoch 41/100000\n",
      " - 1s - loss: 0.0134 - accuracy: 0.1389\n",
      "Epoch 42/100000\n",
      " - 1s - loss: 0.0123 - accuracy: 0.1457\n",
      "Epoch 43/100000\n",
      " - 1s - loss: 0.0125 - accuracy: 0.1454\n",
      "Epoch 44/100000\n",
      " - 1s - loss: 0.0101 - accuracy: 0.1508\n",
      "Epoch 45/100000\n",
      " - 1s - loss: 0.0087 - accuracy: 0.1577\n",
      "Epoch 46/100000\n",
      " - 1s - loss: 0.0092 - accuracy: 0.1491\n",
      "Epoch 47/100000\n",
      " - 1s - loss: 0.0090 - accuracy: 0.1494\n",
      "Epoch 48/100000\n",
      " - 1s - loss: 0.0105 - accuracy: 0.1496\n",
      "Epoch 49/100000\n",
      " - 1s - loss: 0.0088 - accuracy: 0.1604\n",
      "Epoch 50/100000\n",
      " - 1s - loss: 0.0089 - accuracy: 0.1573\n",
      "Epoch 51/100000\n",
      " - 1s - loss: 0.0097 - accuracy: 0.1569\n",
      "Epoch 52/100000\n",
      " - 1s - loss: 0.0104 - accuracy: 0.1477\n",
      "Epoch 53/100000\n",
      " - 1s - loss: 0.0097 - accuracy: 0.1460\n",
      "Epoch 54/100000\n",
      " - 1s - loss: 0.0080 - accuracy: 0.1637\n",
      "Epoch 55/100000\n",
      " - 1s - loss: 0.0080 - accuracy: 0.1665\n",
      "Epoch 56/100000\n",
      " - 1s - loss: 0.0065 - accuracy: 0.1656\n",
      "Epoch 57/100000\n",
      " - 1s - loss: 0.0072 - accuracy: 0.1643\n",
      "Epoch 58/100000\n",
      " - 1s - loss: 0.0090 - accuracy: 0.1653\n",
      "Epoch 59/100000\n",
      " - 1s - loss: 0.0073 - accuracy: 0.1634\n",
      "Epoch 60/100000\n",
      " - 1s - loss: 0.0116 - accuracy: 0.1492\n",
      "Epoch 61/100000\n",
      " - 1s - loss: 0.0082 - accuracy: 0.1730\n",
      "Epoch 62/100000\n",
      " - 1s - loss: 0.0085 - accuracy: 0.1655\n",
      "Epoch 63/100000\n",
      " - 1s - loss: 0.0086 - accuracy: 0.1608\n",
      "Epoch 64/100000\n",
      " - 1s - loss: 0.0079 - accuracy: 0.1706\n",
      "Epoch 65/100000\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainx, trainy, epochs=100000, verbose=2)\n",
    "_, accuracy = model.evaluate(validx, validy)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(trainx, trainy, model):\n",
    "    mp.plot(model.predict(np.array([trainx]))[0])\n",
    "    mp.plot([trainx[i]/max(trainx) for i in range(bins - 1)])\n",
    "    mp.plot(trainy)\n",
    "    mp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(trainx[300], trainy[300], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
